{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rutina: ActualizacionDiaria.py\n",
    "\n",
    "Descripción:\n",
    "El objetivo de esta rutina es conectarse a la API de combustibles de la Comisión Nacional de Energía\n",
    "(CNE) para luego dar formato a los datos y cargarlos en la base de datos Estudios del DataWareHouse.\n",
    "\n",
    "@author:hector.garrido\n",
    "Correo electrónico: hector.garrido@chilecompra.cl\n",
    "Fecha de creación: Miércoles 4 de noviembre de 2020\n",
    "Fecha de actualización: Miércoles 8 de mayo de 2024\n",
    "\n",
    "Funciones:\n",
    "- get_auth_token: genera el token mediante el método HTTP POST \n",
    "- make_authenticated_request: Obtiene los datos mediante el método HTTP GET\n",
    "- transform_json_to_dataframe: toma los datos desde la API (json) y los formatea para su carga en el DataWareHouse\n",
    "- cargar_y_modificar_aux: carga y modifica tabla auxiliar de carga de datos\n",
    "- elimina_duplicados: Elimina duplicados antes de realizar la carga en la tabla histórica\n",
    "- insert_new_eds: Inserta datos de estaciones de servicio nuevas \n",
    "- update_hist: Actualiza tabla históricas con nuevos datos depurados \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os  # Módulo para interactuar con el sistema operativo, proporciona funciones para trabajar con archivos, directorios, variables de entorno, etc.\n",
    "import numpy as np  # Biblioteca para computación numérica en Python, proporciona estructuras de datos y funciones para trabajar con matrices y vectores de manera eficiente.\n",
    "import pandas as pd  # Biblioteca para análisis y manipulación de datos en Python, proporciona la estructura de datos DataFrame para trabajar con conjuntos de datos tabulares.\n",
    "pd.options.mode.chained_assignment = None  # Configuración para suprimir los warnings de \"copia encadenada\" en pandas, para evitar posibles advertencias que no son relevantes en nuestro código.\n",
    "import requests as r  # Biblioteca para enviar solicitudes HTTP en Python, facilita la realización de solicitudes a servidores web y el manejo de respuestas.\n",
    "import sqlalchemy as sa  # Biblioteca para interactuar con bases de datos relacionales en Python, proporciona herramientas para conectarse a bases de datos, enviar consultas SQL, etc.\n",
    "from sqlalchemy.sql import text  # Clase para construir expresiones SQL en SQLAlchemy, útil para generar consultas SQL de manera programática.\n",
    "from sqlalchemy.types import NVARCHAR  # Tipo de datos específico de SQLAlchemy, usado para definir columnas de tipo NVARCHAR en bases de datos SQL Server.\n",
    "import urllib  # Módulo para trabajar con URL en Python, proporciona funciones para manipular URLs, codificar y decodificar componentes de URL, etc.\n",
    "import json  # Módulo para trabajar con datos JSON en Python, proporciona funciones para codificar y decodificar datos JSON.\n",
    "from datetime import date  # Clase para representar fechas en Python, útil para manipular y trabajar con fechas en nuestras aplicaciones.\n",
    "from datetime import timedelta  # Clase para representar duraciones de tiempo en Python, útil para calcular y manipular intervalos de tiempo.\n",
    "import urllib                        #Para formatear string de conexión\n",
    "\n",
    "\n",
    "param_DW = urllib.parse.quote_plus(\"DRIVER={ODBC Driver 17 for SQL Server};SERVER=10.34.71.202;UID=datawarehouse;PWD=datawarehouse;DATABASE=Estudios;TrustServerCertificate=yes\")\n",
    "engine = sa.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % param_DW)\n",
    "\n",
    "url = \"https://api.cne.cl/api/login\"\n",
    "email = \"hectorgarridohenriquez@gmail.com\"\n",
    "password = \"r2ikSGpgwetgjAk\"\n",
    "\n",
    "def get_auth_token(email, password):\n",
    "    url = \"https://api.cne.cl/api/login\"\n",
    "    response = r.post(\n",
    "        url,\n",
    "        json={\"email\": email, \"password\": password}\n",
    "    )\n",
    "    return response.json()[\"token\"]\n",
    "\n",
    "token = get_auth_token(email, password)\n",
    "\n",
    "# Función para hacer una solicitud autenticada utilizando el token\n",
    "def make_authenticated_request(token, endpoint):\n",
    "    url = \"https://api.cne.cl\" + endpoint\n",
    "    response = r.get(\n",
    "        url,\n",
    "        headers={\"Authorization\": \"Bearer \" + token}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "resp = make_authenticated_request(token, \"/api/v4/estaciones\")\n",
    "\n",
    "\n",
    "def transform_json_to_dataframe(resp):\n",
    "    # Crear DataFrame a partir del json\n",
    "    estaciones_df = pd.DataFrame(resp)\n",
    "    \n",
    "    # Agregar columna de fecha actual\n",
    "    hoy = date.today()\n",
    "    estaciones_df['fecha_subida'] = hoy\n",
    "    \n",
    "    # Agregar columnas de precios por combustible y otras columnas\n",
    "    estaciones_df['precio93'] = np.nan\n",
    "    estaciones_df['precio95'] = np.nan\n",
    "    estaciones_df['precio97'] = np.nan\n",
    "    estaciones_df['precio_diesel'] = np.nan\n",
    "    estaciones_df['proveedor'] = np.nan\n",
    "    estaciones_df['latitud'] = np.nan\n",
    "    estaciones_df['longitud'] = np.nan\n",
    "    estaciones_df['direccion_calle'] = np.nan\n",
    "\n",
    "    # Iterar sobre cada fila del DataFrame para asignar los precios y otras columnas\n",
    "    for i in range(len(estaciones_df)):\n",
    "        precios = estaciones_df['precios'][i]\n",
    "        if isinstance(precios, dict):\n",
    "            if '93' in precios.keys():\n",
    "                estaciones_df.loc[i, 'precio93'] = precios['93']['precio']\n",
    "                estaciones_df.loc[i,'fecha_actualizacion'] = precios['93']['fecha_actualizacion']\n",
    "                estaciones_df.loc[i,'hora_actualizacion'] = precios['93']['hora_actualizacion']\n",
    "            if '95' in precios.keys():\n",
    "                estaciones_df.loc[i, 'precio95'] = precios['95']['precio']\n",
    "                estaciones_df.loc[i,'fecha_actualizacion'] = precios['95']['fecha_actualizacion']\n",
    "                estaciones_df.loc[i,'hora_actualizacion'] = precios['95']['hora_actualizacion']    \n",
    "            if '97' in precios.keys():\n",
    "                estaciones_df.loc[i, 'precio97'] = precios['97']['precio']\n",
    "                estaciones_df.loc[i,'fecha_actualizacion'] = precios['97']['fecha_actualizacion']\n",
    "                estaciones_df.loc[i,'hora_actualizacion'] = precios['97']['hora_actualizacion']\n",
    "            if 'DI' in precios.keys():\n",
    "                estaciones_df.loc[i, 'precio_diesel'] = precios['DI']['precio']\n",
    "                estaciones_df.loc[i,'fecha_actualizacion'] = precios['DI']['fecha_actualizacion']\n",
    "                estaciones_df.loc[i,'hora_actualizacion'] = precios['DI']['hora_actualizacion']\n",
    "            estaciones_df.loc[i, 'proveedor'] = estaciones_df['distribuidor'][i]['marca']\n",
    "            estaciones_df.loc[i, 'latitud'] = estaciones_df['ubicacion'][i]['latitud']\n",
    "            estaciones_df.loc[i, 'longitud'] = estaciones_df['ubicacion'][i]['longitud']\n",
    "            estaciones_df.loc[i, 'direccion_calle'] = estaciones_df['ubicacion'][i]['direccion']\n",
    "    \n",
    "    # Eliminar filas donde todos los precios son NaN\n",
    "    missing_all_prices = (estaciones_df['precio93'].isna()\n",
    "                          & estaciones_df['precio95'].isna()\n",
    "                          & estaciones_df['precio97'].isna()\n",
    "                          & estaciones_df['precio_diesel'].isna())\n",
    "    estaciones_df = estaciones_df[~missing_all_prices]\n",
    "    \n",
    "    # Renombrar columnas y realizar otras transformaciones\n",
    "    estaciones_df = estaciones_df.rename(columns={'codigo': 'id'})\n",
    "    estaciones_df['id'] = estaciones_df['id'].str.strip()\n",
    "    estaciones_df['id_est_fecha']= estaciones_df['id'] + estaciones_df['fecha_subida'].astype(str)\n",
    "    estaciones_df['id_est_fecha'] = estaciones_df['id_est_fecha'].str.replace(\"-\",\"\")\n",
    "    first_col = estaciones_df.pop(\"id_est_fecha\")\n",
    "    estaciones_df.insert(0, \"id_est_fecha\", first_col)\n",
    "    col_aux = estaciones_df.pop(\"proveedor\")\n",
    "    estaciones_df.insert(2, \"proveedor\", col_aux)\n",
    "    estaciones_df = estaciones_df.drop(['precios','razon_social','direccion_calle','horario_atencion',\n",
    "             'distribuidor', 'metodos_de_pago', 'ubicacion','servicios','punto_electrico' ], axis = 1)\n",
    "    \n",
    "    # Crear DataFrames individuales para cada tipo de combustible\n",
    "    c93_df = estaciones_df[[\"id\",\"fecha_actualizacion\",\"fecha_subida\", \"precio93\",'hora_actualizacion']]\n",
    "    c93_df = c93_df.rename(columns = {\"precio93\":\"precio\" , \"fecha_actualizacion\":\"fecha_inicio\",\n",
    "                                      \"fecha_subida\": \"fecha_fin\"}) \n",
    "    c93_df.dropna(subset = [\"precio\"], inplace=True)\n",
    "    c93_df['tipo'] = 'Bencina93'\n",
    "\n",
    "    c95_df = estaciones_df[[\"id\",\"fecha_actualizacion\",\"fecha_subida\", \"precio95\",'hora_actualizacion']]\n",
    "    c95_df = c95_df.rename(columns = {\"precio95\":\"precio\" , \"fecha_actualizacion\":\"fecha_inicio\",\n",
    "                                      \"fecha_subida\": \"fecha_fin\"}) \n",
    "    c95_df.dropna(subset = [\"precio\"], inplace=True)\n",
    "    c95_df['tipo'] = 'Bencina95'\n",
    "\n",
    "    c97_df = estaciones_df[[\"id\",\"fecha_actualizacion\",\"fecha_subida\", \"precio97\",'hora_actualizacion']]\n",
    "    c97_df = c97_df.rename(columns = {\"precio97\":\"precio\" , \"fecha_actualizacion\":\"fecha_inicio\",\n",
    "                                      \"fecha_subida\": \"fecha_fin\"}) \n",
    "    c97_df.dropna(subset = [\"precio\"], inplace=True)\n",
    "    c97_df['tipo'] = 'Bencina97'\n",
    "\n",
    "    c_diesel_df = estaciones_df[[\"id\",\"fecha_actualizacion\", \"fecha_subida\",\"precio_diesel\",'hora_actualizacion']]\n",
    "    c_diesel_df = c_diesel_df.rename(columns = {\"precio_diesel\":\"precio\" , \"fecha_actualizacion\":\"fecha_inicio\",\n",
    "                                      \"fecha_subida\": \"fecha_fin\"}) \n",
    "    c_diesel_df.dropna(subset = [\"precio\"], inplace=True)\n",
    "    c_diesel_df['tipo'] = 'Diesel'\n",
    "    \n",
    "    # Almacenar los DataFrames en un diccionario\n",
    "    result = {\n",
    "        'c93_df': c93_df,\n",
    "        'c95_df': c95_df,\n",
    "        'c97_df': c97_df,\n",
    "        'c_diesel_df': c_diesel_df,\n",
    "        'eds':estaciones_df\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "data_frames = transform_json_to_dataframe(resp)\n",
    "\n",
    "\n",
    "c93_df = data_frames['c93_df']  # Accede al DataFrame de Bencina 93\n",
    "c95_df = data_frames['c95_df']  # Accede al DataFrame de Bencina 95\n",
    "c97_df = data_frames['c97_df']  # Accede al DataFrame de Bencina 97\n",
    "c_diesel_df = data_frames['c_diesel_df']  # Accede al DataFrame de Diesel\n",
    "def cargar_y_modificar_aux(tabla_aux, datos):\n",
    "    # Paso 1: Modificar la tabla auxiliar\n",
    "    with engine.connect() as conn:\n",
    "        trans = conn.begin()\n",
    "        try:\n",
    "            # Borrar los datos existentes\n",
    "            conn.execute(text(f'''\n",
    "            DELETE FROM Estudios.dbo.{tabla_aux}\n",
    "            '''))\n",
    "\n",
    "            # Alterar la tabla para añadir la columna 'hora_actualizacion'\n",
    "            #conn.execute(text(f'''\n",
    "            #ALTER TABLE {tabla_aux}\n",
    "            #ADD hora_actualizacion TIME;\n",
    "            #'''))\n",
    "            \n",
    "            trans.commit()\n",
    "        except:\n",
    "            trans.rollback()\n",
    "            raise\n",
    "\n",
    "    # Paso 2: Cargar los nuevos datos en la tabla auxiliar\n",
    "    datos.to_sql(tabla_aux, con=engine, if_exists='append', index=False, dtype={\n",
    "        'id': sa.types.NVARCHAR(length=50),\n",
    "        'precio': sa.types.Float(),\n",
    "        'tipo': sa.types.NVARCHAR(length=50),\n",
    "        'fecha_inicio': sa.types.Date(),\n",
    "        'fecha_fin': sa.types.Date(),\n",
    "        'hora_actualizacion': sa.types.Time()\n",
    "    })\n",
    "\n",
    "# Ejemplo de uso\n",
    "cargar_y_modificar_aux(\"Bencina93Aux\", c93_df)\n",
    "cargar_y_modificar_aux(\"Bencina95Aux\",c95_df)\n",
    "cargar_y_modificar_aux(\"Bencina97Aux\",c97_df)\n",
    "cargar_y_modificar_aux(\"DieselAux\",c_diesel_df)\n",
    "#Elimina observaciones duplicadas en la tabla auxiliar \n",
    "\n",
    "def elimina_duplicados(table_aux,table_ant):\n",
    "    with engine.connect() as conn:\n",
    "        trans = conn.begin()\n",
    "        try:\n",
    "            conn.execute(\n",
    "                text(\n",
    "                f'''\n",
    "                DELETE b\n",
    "                FROM Estudios.dbo.{table_aux} b\n",
    "                INNER JOIN Estudios.dbo.{table_ant} a\n",
    "                ON a.id = b.id \n",
    "                AND a.fecha_inicio = b.fecha_inicio \n",
    "                AND a.precio = b.precio;\n",
    "                '''\n",
    "                )\n",
    "            )\n",
    "            trans.commit()\n",
    "        except Exception as e:\n",
    "            trans.rollback()\n",
    "            print(f\"Ha ocurrido un error al momento de modificar {table_aux}:{e}\")\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "elimina_duplicados(\"Bencina93Aux\",\"Bencina93Anterior\")\n",
    "elimina_duplicados(\"Bencina95Aux\",\"Bencina95Anterior\")\n",
    "elimina_duplicados(\"Bencina97Aux\",\"Bencina97Anterior\")\n",
    "elimina_duplicados(\"DieselAux\",\"DieselAnterior\")\n",
    "\n",
    "# CASO N°1: Estaciones nuevas se insertan\n",
    "##Se inserta dentro de la tabla histórica, todos los elementos de la tabla de \n",
    "##elementos nuevos de la tabla auxiliar\n",
    "\n",
    "def insert_new_eds(table_aux, table_hist, table_ant):\n",
    "    with engine.connect() as conn:\n",
    "        trans = conn.begin()\n",
    "        try:\n",
    "            conn.execute(text(\n",
    "                f'''\n",
    "                INSERT INTO [Estudios].[dbo].{table_hist} (id, fecha_inicio, fecha_fin, precio, tipo)\n",
    "                SELECT a.id, a.fecha_inicio, a.fecha_fin, a.precio, a.tipo\n",
    "                FROM [Estudios].[dbo].{table_aux} AS a\n",
    "                LEFT JOIN [Estudios].[dbo].{table_ant} AS b\n",
    "                ON a.id = b.id\n",
    "                WHERE b.id IS NULL\n",
    "                '''\n",
    "            ))\n",
    "            trans.commit()\n",
    "        except Exception as e:\n",
    "            trans.rollback()\n",
    "            print(f\"Ha ocurrido un error al insertar en la tabla {table_hist}: {e}\")\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "\n",
    "insert_new_eds('Bencina93Aux','Bencina93Hist','Bencina93Anterior')\n",
    "insert_new_eds('Bencina95Aux','Bencina95Hist','Bencina95Anterior')\n",
    "insert_new_eds('Bencina97Aux','Bencina97Hist','Bencina97Anterior')\n",
    "insert_new_eds('DieselAux','DieselHist','DieselAnterior')\n",
    "\n",
    "# CASO N°2: Se insertan todas las nuevas observaciones de estaciones ya existentes\n",
    "\n",
    "def update_hist(table_ant, table_hist, table_aux):\n",
    "    with engine.connect() as conn:\n",
    "        trans = conn.begin()\n",
    "        try:\n",
    "            conn.execute(text(\n",
    "            f'''\n",
    "            WITH temp AS (\n",
    "                SELECT \n",
    "                    b.id,\n",
    "                    MAX(fecha_inicio) AS [fecha_inicio]\n",
    "                FROM estudios.dbo.{table_ant} b\n",
    "                GROUP BY b.id\n",
    "            )\n",
    "\n",
    "            INSERT INTO estudios.dbo.{table_hist} (id, fecha_inicio, fecha_fin, precio, tipo)\n",
    "            SELECT \n",
    "                a.id,\n",
    "                a.fecha_inicio,\n",
    "                a.fecha_fin,\n",
    "                a.precio,\n",
    "                a.tipo\n",
    "            FROM estudios.dbo.{table_aux} AS a\n",
    "            INNER JOIN temp b ON a.id = b.id\n",
    "            WHERE a.fecha_inicio > b.fecha_inicio\n",
    "            ORDER BY a.fecha_inicio ASC;\n",
    "\n",
    "                                    '''\n",
    "            ))\n",
    "            trans.commit()\n",
    "        except Exception as e:\n",
    "            trans.rollback()\n",
    "            print(f\"Ha ocurrido un error al actualizar la tabla {table_hist}:{e}\")\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "update_hist('Bencina93Anterior','Bencina93Hist','Bencina93Aux')\n",
    "update_hist('Bencina95Anterior','Bencina95Hist','Bencina95Aux')\n",
    "update_hist('Bencina97Anterior','Bencina97Hist','Bencina97Aux')\n",
    "update_hist('DieselAnterior','DieselHist','DieselAux')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
